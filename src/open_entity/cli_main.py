#!/usr/bin/env python3
"""Moco CLI"""

# ruff: noqa: E402
import warnings
# ========================================
# è­¦å‘Šã®æŠ‘åˆ¶ (ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰ã«è¨­å®š)
# ========================================
# Python 3.9 EOL ã‚„ SSL é–¢é€£ã®ä¸è¦ãªè­¦å‘Šã‚’éè¡¨ç¤ºã«ã™ã‚‹
warnings.filterwarnings("ignore", category=FutureWarning)
try:
    # urllib3 ã® NotOpenSSLWarning ã¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«ç™ºç”Ÿã™ã‚‹ãŸã‚ã€
    # è­¦å‘Šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å…ˆã«è¨­å®šã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹
    warnings.filterwarnings("ignore", message=".*urllib3 v2 only supports OpenSSL 1.1.1+.*")
    # Google GenAI ã® thought_signature è­¦å‘Šã‚’æŠ‘åˆ¶
    warnings.filterwarnings("ignore", message=".*non-text parts in the response.*")
    warnings.filterwarnings("ignore", message=".*thought_signature.*")
except Exception:
    pass

# ========================================
# é‡è¦: .env ã®èª­ã¿è¾¼ã¿ã¯æœ€åˆã«è¡Œã†å¿…è¦ãŒã‚ã‚‹
# ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«ç’°å¢ƒå¤‰æ•°ã‚’å‚ç…§ã™ã‚‹ãŸã‚
# ========================================
import os
from pathlib import Path
from dotenv import load_dotenv, find_dotenv

def _early_load_dotenv():
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰ã« .env ã‚’èª­ã¿è¾¼ã‚€"""
    env_path = find_dotenv(usecwd=True) or (Path(__file__).parent.parent.parent / ".env")
    if env_path:
        load_dotenv(env_path)

# ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹å‰ã«ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
_early_load_dotenv()

# ã“ã“ã‹ã‚‰é€šå¸¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import typer
import time
import sys
from datetime import datetime
from typing import Optional, List
from .ui.theme import ThemeName, THEMES

def init_environment():
    """ç’°å¢ƒå¤‰æ•°ã®åˆæœŸåŒ–ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ®‹ã™ï¼‰"""
    # æ—¢ã« _early_load_dotenv() ã§èª­ã¿è¾¼ã¿æ¸ˆã¿ã ãŒã€
    # æ˜ç¤ºçš„ã«å‘¼ã°ã‚ŒãŸå ´åˆã¯å†èª­ã¿è¾¼ã¿
    env_path = find_dotenv(usecwd=True) or (Path(__file__).parent.parent.parent / ".env")
    if env_path:
        load_dotenv(env_path, override=True)


def resolve_provider(provider_str: str, model: Optional[str] = None) -> tuple:
    """ãƒ—ãƒ­ãƒã‚¤ãƒ€æ–‡å­—åˆ—ã‚’è§£æ±ºã—ã¦LLMProviderã¨ãƒ¢ãƒ‡ãƒ«åã‚’è¿”ã™
    
    Args:
        provider_str: ãƒ—ãƒ­ãƒã‚¤ãƒ€æ–‡å­—åˆ— (ä¾‹: "gemini", "zai/glm-4.7")
        model: ãƒ¢ãƒ‡ãƒ«åï¼ˆæ—¢ã«æŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    
    Returns:
        tuple: (LLMProvider, model_name) - ç„¡åŠ¹ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ã®å ´åˆã¯ typer.Exit ã‚’ç™ºç”Ÿ
    """
    from .core.runtime import LLMProvider
    
    # "zai/glm-4.7" ã®ã‚ˆã†ãªå½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
    provider_name = provider_str
    resolved_model = model
    if "/" in provider_str and model is None:
        parts = provider_str.split("/", 1)
        provider_name = parts[0]
        resolved_model = parts[1]
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€åã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒãƒƒãƒ”ãƒ³ã‚°
    VALID_PROVIDERS = {
        "openai": LLMProvider.OPENAI,
        "openrouter": LLMProvider.OPENROUTER,
        "zai": LLMProvider.ZAI,
        "gemini": LLMProvider.GEMINI,
        "moonshot": LLMProvider.MOONSHOT,
        "ollama": LLMProvider.OLLAMA,
    }
    
    if provider_name not in VALID_PROVIDERS:
        valid_list = ", ".join(sorted(VALID_PROVIDERS.keys()))
        typer.echo(f"Error: Unknown provider '{provider_name}'. Valid options: {valid_list}", err=True)
        raise typer.Exit(code=1)
    
    return VALID_PROVIDERS[provider_name], resolved_model


app = typer.Typer(
    name="Open Entity",
    help="Lightweight AI agent orchestration framework",
    add_completion=False,
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ç”¨ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ï¼ˆcommandsã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
from .commands.sessions import sessions_app
app.add_typer(sessions_app, name="sessions")

# Skills ç®¡ç†ç”¨ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ï¼ˆcommandsã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
from .commands.skills import skills_app
app.add_typer(skills_app, name="skills")

# ã‚¿ã‚¹ã‚¯ç®¡ç†ç”¨ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ï¼ˆcommandsã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
from .commands.tasks import tasks_app
app.add_typer(tasks_app, name="tasks")

# è‡ªå·±é€²åŒ–ã‚³ãƒãƒ³ãƒ‰ï¼ˆcommandsã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
from .commands.evolve import evolve_app
app.add_typer(evolve_app, name="evolve")

# A2Aé€šä¿¡ã‚³ãƒãƒ³ãƒ‰ï¼ˆP2Pï¼‰
from .commands.a2a import a2a_app
app.add_typer(a2a_app, name="a2a")

# profilesã‚³ãƒãƒ³ãƒ‰ã‚’ç™»éŒ²ï¼ˆlist-profiles, versionç­‰ï¼‰
from .commands.profiles import register_commands
register_commands(app)


def get_available_profiles() -> List[str]:
    """åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    profiles = []
    
    # 1. ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® profiles/
    cwd_profiles = Path.cwd() / "profiles"
    if cwd_profiles.exists():
        for p in cwd_profiles.iterdir():
            if p.is_dir() and (p / "profile.yaml").exists():
                profiles.append(p.name)
    
    # 2. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å†…è”µãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    pkg_profiles = Path(__file__).parent / "profiles"
    if pkg_profiles.exists():
        for p in pkg_profiles.iterdir():
            if p.is_dir() and (p / "profile.yaml").exists():
                if p.name not in profiles:
                    profiles.append(p.name)
    
    return sorted(profiles) if profiles else ["default"]


def complete_profile(incomplete: str) -> List[str]:
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚¿ãƒ–è£œå®Œ"""
    profiles = get_available_profiles()
    return [p for p in profiles if p.startswith(incomplete)]


def prompt_profile_selection() -> str:
    """å¯¾è©±çš„ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ"""
    from rich.console import Console
    from rich.prompt import Prompt
    
    console = Console()
    profiles = get_available_profiles()
    
    if len(profiles) == 1:
        return profiles[0]
    
    console.print("\n[bold]Available profiles:[/]")
    for i, p in enumerate(profiles, 1):
        console.print(f"  [cyan]{i}[/]. {p}")
    
    choice = Prompt.ask(
        "\n[bold]Select profile[/]",
        choices=[str(i) for i in range(1, len(profiles) + 1)] + profiles,
        default="1"
    )
    
    # æ•°å­—ã§é¸æŠã•ã‚ŒãŸå ´åˆ
    if choice.isdigit():
        idx = int(choice) - 1
        if 0 <= idx < len(profiles):
            return profiles[idx]
    
    # åå‰ã§é¸æŠã•ã‚ŒãŸå ´åˆ
    if choice in profiles:
        return choice
    
    return profiles[0]


@app.command()
def run(
    task: str = typer.Argument(..., help="å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¹ã‚¯"),
    profile: str = typer.Option("default", "--profile", "-p", help="ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«", autocompletion=complete_profile),
    provider: Optional[str] = typer.Option(None, "--provider", "-P", help="LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ (gemini/openai/openrouter/zai/moonshot/ollama) - çœç•¥æ™‚ã¯è‡ªå‹•é¸æŠ"),
    model: Optional[str] = typer.Option(None, "--model", "-m", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å (ä¾‹: gpt-4o, gemini-2.5-pro, claude-sonnet-4)"),
    stream: bool = typer.Option(False, "--stream/--no-stream", help="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚ªãƒ•ï¼‰"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="è©³ç´°ãƒ­ã‚°"),
    rich_output: bool = typer.Option(True, "--rich/--plain", help="ãƒªãƒƒãƒå‡ºåŠ›"),
    session: Optional[str] = typer.Option(None, "--session", "-s", help="ã‚»ãƒƒã‚·ãƒ§ãƒ³åï¼ˆç¶™ç¶š or æ–°è¦ï¼‰"),
    cont: bool = typer.Option(False, "--continue", "-c", help="ç›´å‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç¶™ç¶š"),
    auto_retry: int = typer.Option(0, "--auto-retry", help="ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤å›æ•°"),
    retry_delay: int = typer.Option(3, "--retry-delay", help="ãƒªãƒˆãƒ©ã‚¤é–“éš”ï¼ˆç§’ï¼‰"),
    show_metrics: bool = typer.Option(False, "--show-metrics", "-M", help="ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º"),
    theme: ThemeName = typer.Option(ThemeName.DEFAULT, "--theme", help="UIã‚«ãƒ©ãƒ¼ãƒ†ãƒ¼ãƒ", case_sensitive=False),
    use_optimizer: bool = typer.Option(False, "--optimizer/--no-optimizer", help="Optimizerã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªå‹•é¸æŠ"),
    working_dir: Optional[str] = typer.Option(None, "--working-dir", "-w", help="ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆsubagentã«è‡ªå‹•ä¼é”ï¼‰"),
):
    """ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ"""
    if session and cont:
        typer.echo("Error: --session ã¨ --continue ã¯åŒæ™‚ã«æŒ‡å®šã§ãã¾ã›ã‚“ã€‚", err=True)
        raise typer.Exit(code=1)

    from .ui.layout import ui_state
    ui_state.theme = theme

    theme_config = THEMES[theme]

    init_environment()

    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨è¨­å®š
    if working_dir:
        path = Path(working_dir).resolve()
        if not path.is_dir():
            typer.echo(f"Error: Directory does not exist: {working_dir}", err=True)
            raise typer.Exit(code=1)
        os.environ['MOCO_WORKING_DIRECTORY'] = str(path)

    from .core.orchestrator import Orchestrator
    from .core.llm_provider import get_available_provider

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è§£æ±ºï¼ˆæŒ‡å®šãªã—ã®å ´åˆã¯å„ªå…ˆé †ä½ã§è‡ªå‹•é¸æŠï¼‰
    if provider is None:
        provider = get_available_provider()

    provider_enum, model = resolve_provider(provider, model)

    if rich_output:
        from rich.console import Console
        from rich.panel import Panel
        console = Console()

    o = Orchestrator(
        profile=profile,
        provider=provider_enum,
        model=model,
        stream=stream,
        verbose=verbose,
        use_optimizer=use_optimizer,
        working_directory=working_dir,
    )

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
    session_id = None
    if cont:
        # ç›´å‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—
        sessions = o.session_logger.list_sessions(limit=1)
        if sessions:
            session_id = sessions[0].get("session_id")
            if rich_output:
                console.print(f"[dim]Continuing session: {session_id[:8]}...[/dim]")
        else:
            typer.echo("Warning: ç¶™ç¶šã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚", err=True)
    elif session:
        # åå‰ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢ã¾ãŸã¯ä½œæˆ
        sessions = o.session_logger.list_sessions(limit=50)
        for s in sessions:
            if s.get("title", "").endswith(f"[{session}]"):
                session_id = s.get("session_id")
                if rich_output:
                    console.print(f"[dim]Resuming session: {session}[/dim]")
                break

    if not session_id:
        title = f"CLI: {task[:40]}" + (f" [{session}]" if session else "")
        session_id = o.create_session(title=title)

    if rich_output:
        header = f"[bold {theme_config.status}]Profile:[/] {profile}  [bold {theme_config.status}]Provider:[/] {provider}"
        if session:
            header += f"  [bold {theme_config.status}]Session:[/] {session}"
        console.print(Panel(header, title="ğŸ¤– Moco", border_style=theme_config.tools))
        console.print()

    # å®Ÿè¡Œï¼ˆãƒªãƒˆãƒ©ã‚¤å¯¾å¿œï¼‰
    start_time = time.time()
    result = None

    from .cancellation import create_cancel_event, request_cancel, clear_cancel_event, OperationCancelled
    create_cancel_event(session_id)

    try:
        for attempt in range(auto_retry + 1):
            try:
                result = o.run_sync(task, session_id)
                break
            except (KeyboardInterrupt, OperationCancelled):
                request_cancel(session_id)
                if rich_output:
                    console.print(f"\n[bold red]Cancelled[/bold red] (Session: {session_id[:8]}...)")
                else:
                    print(f"\nCancelled (Session: {session_id[:8]}...)")
                raise typer.Exit(code=0)
            except Exception as e:
                if attempt < auto_retry:
                    if rich_output:
                        console.print(f"[yellow]Error: {e}. Retrying in {retry_delay}s... ({attempt + 1}/{auto_retry})[/yellow]")
                    time.sleep(retry_delay)
                else:
                    if rich_output:
                        console.print(f"[red]Error: {e}[/red]")
                        _print_error_hints(console, e)
                    raise typer.Exit(code=1)
    finally:
        clear_cancel_event(session_id)

    elapsed = time.time() - start_time

    if rich_output and result:
        console.print()
        _print_result(console, result, theme_name=theme, verbose=verbose)

        if show_metrics:
            console.print()
            console.print(Panel(
                f"[bold]Elapsed:[/] {elapsed:.1f}s\n"
                f"[bold]Session:[/] {session_id[:8]}...",
                title="ğŸ“Š Metrics",
                border_style=theme_config.status,
            ))
    elif result:
        print("\n--- Result ---")
        print(result)




def _print_error_hints(console, error: Exception):
    """ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã«å¿œã˜ãŸãƒ’ãƒ³ãƒˆã‚’è¡¨ç¤º"""
    from rich.panel import Panel

    error_str = str(error).lower()
    hints = []

    if "rate limit" in error_str or "429" in error_str:
        hints.append("â€¢ ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã§ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        hints.append("â€¢ --provider ã‚’å¤‰æ›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
    elif "api key" in error_str or "authentication" in error_str:
        hints.append("â€¢ API ã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        hints.append("â€¢ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«æ­£ã—ã„ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã€‚")
    elif "context" in error_str or "token" in error_str:
        hints.append("â€¢ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        hints.append("â€¢ ã‚¿ã‚¹ã‚¯ã‚’åˆ†å‰²ã—ã¦å®Ÿè¡Œã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
    else:
        hints.append("â€¢ --verbose ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§è©³ç´°ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        hints.append("â€¢ --auto-retry ã§ãƒªãƒˆãƒ©ã‚¤ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")

    console.print(Panel("\n".join(hints), title="ğŸ’¡ Hints", border_style="yellow"))


def _print_result(console, result: str, theme_name: ThemeName = ThemeName.DEFAULT, verbose: bool = False):
    """çµæœã‚’æ•´å½¢ã—ã¦è¡¨ç¤ºï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ï¼‰

    Args:
        console: Rich console
        result: çµæœæ–‡å­—åˆ—
        verbose: True ãªã‚‰å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡ºåŠ›ã‚’è¡¨ç¤ºã€False ãªã‚‰æœ€å¾Œã ã‘
    """
    import re

    theme = THEMES[theme_name]

    # æœ€çµ‚ã‚µãƒãƒªãƒ¼ã‚’æŠ½å‡º
    final_summary = ""
    if "\n---\n## ã¾ã¨ã‚" in result:
        parts = result.split("\n---\n## ã¾ã¨ã‚")
        result = parts[0]
        final_summary = parts[1].strip() if len(parts) > 1 else ""
    elif "\n---\nâœ…" in result:
        parts = result.split("\n---\nâœ…")
        result = parts[0]
        final_summary = parts[1].strip() if len(parts) > 1 else ""

    # @agent: å¿œç­” ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†å‰²
    sections = re.split(r'(@[\w-]+):\s*', result)

    if len(sections) > 1:
        if verbose:
            # å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›ã‚’è¡¨ç¤º
            i = 1
            while i < len(sections):
                agent = sections[i]
                content = sections[i + 1].strip() if i + 1 < len(sections) else ""
                if content:
                    # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
                    lines = content.split('\n')
                    if len(lines) > 30:
                        content = '\n'.join(lines[:30]) + f"\n... ({len(lines) - 30} lines omitted)"
                    console.print(f"\n[bold {theme.thoughts}]{agent}[/]")
                    console.print(content)
                i += 2
        else:
            # æœ€å¾Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã ã‘è¡¨ç¤º
            last_agent = sections[-2] if len(sections) >= 2 else ""
            last_content = sections[-1].strip() if sections[-1] else ""

            # orchestrator ã®æœ€çµ‚å›ç­”ã¯çœç•¥ã—ãªã„ã€ä»–ã¯çŸ­ç¸®
            if last_agent == "@orchestrator":
                display = last_content
            else:
                lines = last_content.split('\n')
                if len(lines) > 20:
                    display = '\n'.join(lines[:20]) + f"\n\n[dim]... ({len(lines) - 20} lines omitted, use -v for full output)[/dim]"
                else:
                    display = last_content

            console.print(f"\n[bold {theme.thoughts}]{last_agent}[/]")
            console.print(display)

    # æœ€çµ‚ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    if final_summary:
        console.print(f"\n[bold {theme.result}]âœ… ã¾ã¨ã‚[/]")
        console.print(final_summary)
    elif len(sections) > 1:
        console.print(f"\n[bold {theme.result}]âœ… å®Œäº†[/]")
    else:
        # å˜ä¸€ã®å¿œç­”
        console.print(result)


@app.command()
def chat(
    profile: Optional[str] = typer.Option(None, "--profile", "-p", help="ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«", autocompletion=complete_profile),
    provider: Optional[str] = typer.Option(None, "--provider", "-P", help="LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ (gemini/openai/openrouter/zai/moonshot/ollama) - çœç•¥æ™‚ã¯è‡ªå‹•é¸æŠ"),
    model: Optional[str] = typer.Option(None, "--model", "-m", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å"),
    stream: Optional[bool] = typer.Option(None, "--stream/--no-stream", help="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒ—ãƒ­ãƒã‚¤ãƒ€ä¾å­˜ï¼‰"),
    subagent_stream: bool = typer.Option(False, "--subagent-stream/--no-subagent-stream", help="ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœ¬æ–‡ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚ªãƒ•ï¼‰"),
    tool_status: bool = typer.Option(True, "--tool-status/--no-tool-status", help="ãƒ„ãƒ¼ãƒ«/å§”è­²ã®çŸ­ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡Œã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚ªãƒ³ï¼‰"),
    todo_pane: bool = typer.Option(False, "--todo-pane/--no-todo-pane", help="Todo ã‚’å³ãƒšã‚¤ãƒ³ã«å¸¸æ™‚è¡¨ç¤ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚ªãƒ•ï¼‰"),
    async_input: bool = typer.Option(False, "--async-input/--no-async-input", help="å‡¦ç†ä¸­ã‚‚å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã¦ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ï¼ˆGemini CLIé¢¨ï¼‰"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="è©³ç´°ãƒ­ã‚°"),
    session: Optional[str] = typer.Option(None, "--session", "-s", help="ã‚»ãƒƒã‚·ãƒ§ãƒ³åï¼ˆç¶™ç¶š or æ–°è¦ï¼‰"),
    new_session: bool = typer.Option(False, "--new", help="æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å¼·åˆ¶é–‹å§‹"),
    theme: ThemeName = typer.Option(ThemeName.DEFAULT, "--theme", help="UIã‚«ãƒ©ãƒ¼ãƒ†ãƒ¼ãƒ", case_sensitive=False),
    use_optimizer: bool = typer.Option(False, "--optimizer/--no-optimizer", help="Optimizerã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªå‹•é¸æŠ"),
):
    """å¯¾è©±å‹ãƒãƒ£ãƒƒãƒˆ"""
    from .ui.layout import ui_state
    ui_state.theme = theme
    theme_config = THEMES[theme]

    init_environment()
    from rich.console import Console

    from .core.orchestrator import Orchestrator
    from .core.llm_provider import get_available_provider
    from .core.runtime import _safe_stream_print

    console = Console()
    stream_flags = {"show_subagent_stream": subagent_stream, "show_tool_status": tool_status}
    # Track whether we have printed any streamed text without a newline recently.
    # Used to avoid mixing tool logs into the middle of a line.
    stream_state = {"mid_line": False}

    # prompt_toolkit printing helpers (used in --async-input mode)
    pt_ansi_print = None

    # Async-input mode (Gemini CLI style):
    # - allow typing next prompts while the current one is processing
    # - enqueue prompts and execute sequentially in a worker thread
    if async_input and todo_pane:
        console.print("[yellow]--async-input is currently incompatible with --todo-pane. Disabling --async-input.[/yellow]")
        async_input = False
    if async_input:
        import sys
        if not sys.stdin.isatty():
            console.print("[yellow]--async-input requires an interactive TTY stdin. Disabling --async-input.[/yellow]")
            async_input = False

    # Optional: side pane for Todos (Rich Live layout)
    pane_state = {
        "enabled": bool(todo_pane),
        "live": None,
        "layout": None,
        "lines": [],
        "max_lines": 500,
    }

    def _pane_append(line: str) -> None:
        if not pane_state["enabled"]:
            return
        if line is None:
            return
        s = str(line)
        if not s:
            return
        # Split to keep rendering stable
        parts = s.splitlines() or [s]
        pane_state["lines"].extend(parts)
        # Trim
        if len(pane_state["lines"]) > pane_state["max_lines"]:
            pane_state["lines"] = pane_state["lines"][-pane_state["max_lines"] :]

    def _pane_update_chat_panel() -> None:
        if not pane_state["enabled"]:
            return
        live = pane_state.get("live")
        layout = pane_state.get("layout")
        if not live or not layout:
            return
        try:
            from rich.panel import Panel
            from rich.text import Text
            from rich import box

            # Auto-follow: render only the bottom-most lines that fit in the panel.
            # (If we render the whole buffer, Rich will show from the top and the latest
            # conversation scrolls out of view.)
            try:
                chat_w = max(20, int(getattr(layout["chat"], "size", None).width or console.size.width) - 4)
                chat_h = max(6, int(getattr(layout["chat"], "size", None).height or console.size.height) - 4)
            except Exception:
                chat_w = max(20, console.size.width - 4)
                chat_h = max(6, console.size.height - 4)

            # Build visible lines from bottom up, accounting for wrapping.
            visible_lines = []
            used_rows = 0
            for ln in reversed(pane_state["lines"][-pane_state["max_lines"] :]):
                try:
                    t = Text.from_markup(ln)
                    plain = t.plain
                except Exception:
                    plain = str(ln)
                # Approximate wrap rows
                rows = max(1, (len(plain) + max(1, chat_w) - 1) // max(1, chat_w))
                if used_rows + rows > chat_h:
                    break
                visible_lines.append(ln)
                used_rows += rows
            visible_lines.reverse()

            text = Text()
            for ln in visible_lines:
                try:
                    text.append_text(Text.from_markup(ln))
                except Exception:
                    text.append(ln)
                text.append("\n")

            layout["chat"].update(
                Panel(
                    text,
                    title="Chat",
                    border_style=theme_config.status,
                    box=box.ROUNDED,
                )
            )
            live.refresh()
        except Exception:
            return

    def _pane_update_todo_panel(session_id: Optional[str]) -> None:
        if not pane_state["enabled"]:
            return
        live = pane_state.get("live")
        layout = pane_state.get("layout")
        if not live or not layout:
            return
        try:
            from rich.panel import Panel
            from rich.text import Text
            from rich import box
            from open_entity.tools.todo import todoread_all, set_current_session

            if session_id:
                set_current_session(session_id)
            raw = todoread_all()
            todo_text = Text(raw or "(no todos)", style="default")
            layout["todo"].update(
                Panel(
                    todo_text,
                    title="Todos",
                    border_style=theme_config.tools,
                    box=box.ROUNDED,
                )
            )
            live.refresh()
        except Exception as e:
            try:
                from rich.panel import Panel
                from rich.text import Text
                from rich import box

                layout["todo"].update(
                    Panel(
                        Text(f"(todo pane error) {e}", style="dim"),
                        title="Todos",
                        border_style=theme_config.tools,
                        box=box.ROUNDED,
                    )
                )
                live.refresh()
            except Exception:
                return

    # Streaming callback for CLI:
    # - tool/delegate logs are printed elsewhere (keep as-is)
    # - print streamed chunks only for orchestrator by default
    def progress_callback(
        event_type: str,
        content: str = None,
        agent_name: str = None,
        **kwargs
    ):
        """
        CLI progress callback.

        Notes:
        - We keep chunk streaming behavior as-is.
        - We additionally surface tool/delegate completion so users can see whether
          write_file/edit_file actually succeeded (or failed).
        """
        # ANSI color code mapping for async-input mode
        _ANSI_COLORS = {
            "black": "30", "red": "31", "green": "32", "yellow": "33",
            "blue": "34", "magenta": "35", "cyan": "36", "white": "37",
            "bright_black": "90", "bright_red": "91", "bright_green": "92",
            "bright_yellow": "93", "bright_blue": "94", "bright_magenta": "95",
            "bright_cyan": "96", "bright_white": "97", "grey50": "90",
        }

        def _get_ansi_code(style: str) -> str:
            """Extract ANSI code from Rich style string."""
            codes = []
            if "bold" in style:
                codes.append("1")
            for color_name, code in _ANSI_COLORS.items():
                if color_name in style:
                    codes.append(code)
                    break
            return ";".join(codes) if codes else "0"

        def _safe_stream_print_styled(text: str, style: str) -> None:
            """Print streamed text with color without breaking streaming."""
            if not text:
                return
            try:
                from rich.text import Text
                if async_input:
                    # Use ANSI escape codes for color in async-input mode
                    ansi_code = _get_ansi_code(style)
                    if ansi_code and ansi_code != "0":
                        _safe_stream_print(f"\x1b[{ansi_code}m{text}\x1b[0m")
                    else:
                        _safe_stream_print(text)
                else:
                    console.print(Text(text, style=style), end="")
            except BrokenPipeError:
                return
            except OSError as e:
                if getattr(e, "errno", None) == 32:
                    return
                _safe_stream_print(text)
            except Exception:
                _safe_stream_print(text)

        # Start marker for orchestrator output (helps distinguish from user input)
        if event_type == "start" and (agent_name or "") == "orchestrator":
            stream_state["thinking_shown"] = False  # Reset thinking flag for new response
            stream_state["thinking_ended"] = False
            if pane_state["enabled"]:
                _pane_append("[bold]ğŸ¤–[/bold] ")
                _pane_update_chat_panel()
                return
            if stream_state.get("mid_line"):
                _safe_stream_print("\n")
                stream_state["mid_line"] = False
            _safe_stream_print_styled("ğŸ¤– ", f"bold {theme_config.result}")
            stream_state["mid_line"] = True
            return

        # Thinking/reasoning content (verbose mode only)
        if event_type == "thinking" and content and verbose:
            if pane_state["enabled"]:
                # Show thinking in pane with dimmed style
                if not stream_state.get("thinking_shown"):
                    _pane_append("[dim]ğŸ’­ Thinking...[/dim]")
                    stream_state["thinking_shown"] = True
                # Don't show full thinking content in pane (too verbose)
                return
            # CLI direct output
            if not stream_state.get("thinking_shown"):
                if async_input and pt_ansi_print:
                    pt_ansi_print("\x1b[2mğŸ’­ Thinking...\x1b[0m")
                else:
                    console.print("[dim]ğŸ’­ Thinking...[/dim]")
                stream_state["thinking_shown"] = True
            # Show thinking content (dimmed)
            if async_input and pt_ansi_print:
                pt_ansi_print(f"\x1b[2m{content}\x1b[0m")
            else:
                console.print(f"[dim]{content}[/dim]", end="")
            return

        # Streamed text chunks
        if event_type == "chunk" and content:
            # End thinking display if it was shown
            if stream_state.get("thinking_shown") and not stream_state.get("thinking_ended"):
                if not pane_state["enabled"]:
                    _safe_stream_print("\n")  # Newline after thinking
                stream_state["thinking_ended"] = True
            name = agent_name or ""
            if name == "orchestrator" or stream_flags.get("show_subagent_stream"):
                if pane_state["enabled"]:
                    # Append to last line (create if needed)
                    if not pane_state["lines"]:
                        pane_state["lines"].append("ğŸ¤– ")
                    chunk = str(content)
                    parts = chunk.split("\n")
                    # First part appends to current last line
                    pane_state["lines"][-1] = (pane_state["lines"][-1] or "") + parts[0]
                    # Remaining parts become new lines
                    for p in parts[1:]:
                        pane_state["lines"].append(p)
                    # Trim
                    if len(pane_state["lines"]) > pane_state["max_lines"]:
                        pane_state["lines"] = pane_state["lines"][-pane_state["max_lines"] :]
                    _pane_update_chat_panel()
                    return
                # Color the assistant output to visually separate it from the user's input line.
                _safe_stream_print_styled(content, theme_config.result)
                stream_state["mid_line"] = True
            return

        # Ensure newline after orchestrator main response
        if event_type == "done":
            if (agent_name or "") == "orchestrator":
                if pane_state["enabled"]:
                    _pane_append("")  # spacing
                    _pane_update_chat_panel()
                    return
                _safe_stream_print("\n")
                stream_state["mid_line"] = False
            return

        # Delegation status (running/completed)
        if event_type == "delegate":
            if not stream_flags.get("show_tool_status", True):
                return
            status = (kwargs.get("status") or "").lower()
            name = kwargs.get("name") or agent_name or ""
            detail = (kwargs.get("detail") or "").strip()
            if name and not str(name).startswith("@"):
                name = f"@{name}"
            if pane_state["enabled"]:
                # Keep default output compact: show only completion unless verbose.
                if status == "running" and verbose:
                    _pane_append(f"[dim]â†’ {name}[/dim]")
                elif status == "completed":
                    _pane_append(f"[green]âœ“ {name}[/green]")
                else:
                    if verbose:
                        _pane_append(f"[dim]{status or 'delegate'} {name}[/dim]")
                _pane_update_chat_panel()
                return
            # If we're mid-stream, start a fresh line to keep logs readable.
            if stream_state.get("mid_line"):
                _safe_stream_print("\n")
                stream_state["mid_line"] = False
            if status == "running":
                if async_input and pt_ansi_print:
                    # Show agent + truncated task text with colors (Gemini CLI style)
                    msg = f"\x1b[2mâ†’\x1b[0m \x1b[36m{name}\x1b[0m"
                    if detail:
                        d = detail.replace("\n", " ").strip()
                        if len(d) > 90:
                            d = d[:87] + "..."
                        msg += f" \x1b[2m{d}\x1b[0m"
                    pt_ansi_print(msg)
                else:
                    console.print(f"[dim]â†’ {name}[/dim]")
            elif status == "completed":
                if async_input and pt_ansi_print:
                    pt_ansi_print(f"\x1b[32mâœ“\x1b[0m \x1b[36m{name}\x1b[0m")
                else:
                    console.print(f"[green]âœ“ {name}[/green]")
            else:
                if async_input and pt_ansi_print:
                    pt_ansi_print(f"\x1b[2m{status or 'delegate'}\x1b[0m \x1b[36m{name}\x1b[0m")
                else:
                    console.print(f"[dim]{status or 'delegate'} {name}[/dim]")
            return

        # Tool status: show running + success/error so file ops are verifiable in-chat.
        if event_type == "tool":
            if not stream_flags.get("show_tool_status", True):
                return
            status = (kwargs.get("status") or "").lower()
            tool_name = kwargs.get("tool_name") or kwargs.get("tool") or ""
            detail = kwargs.get("detail") or ""
            result = kwargs.get("result")

            if pane_state["enabled"]:
                # Default: one line per tool (completed only). Running line only in verbose.
                if status == "running":
                    if verbose:
                        line = tool_name or "tool"
                        if detail:
                            line += f" â†’ {detail}"
                        _pane_append(f"[dim]â†’ {line}[/dim]")
                        _pane_update_chat_panel()
                    return
                if status != "completed":
                    return

                result_str = "" if result is None else str(result)
                is_error = result_str.startswith("Error") or result_str.startswith("ERROR:")
                line = tool_name or "tool"
                if detail:
                    line += f" â†’ {detail}"
                # (No long summary here; keep compact. Verbose summary stays in normal mode.)
                if is_error:
                    _pane_append(f"[red]âœ— {line}[/red]")
                else:
                    _pane_append(f"[green]âœ“ {line}[/green]")
                _pane_update_chat_panel()
                # Refresh todo pane immediately when todos might have changed.
                if tool_name in ("todowrite", "todoread", "todoread_all"):
                    _pane_update_todo_panel(command_context.get("session_id"))
                return

            if stream_state.get("mid_line"):
                _safe_stream_print("\n")
                stream_state["mid_line"] = False

            # Running line (start)
            if status == "running":
                # Default: keep tool-status output compact (one line per tool).
                # Show the "running" line only in verbose mode.
                if verbose:
                    line = tool_name or "tool"
                    if detail:
                        line += f" â†’ {detail}"
                    if async_input and pt_ansi_print:
                        pt_ansi_print(f"\x1b[2mâ†’\x1b[0m \x1b[36m{line}\x1b[0m")
                    else:
                        console.print(f"[dim]â†’ {line}[/dim]")
                return

            if status != "completed":
                return

            # Determine success/failure from result text
            result_str = "" if result is None else str(result)
            is_error = result_str.startswith("Error") or result_str.startswith("ERROR:")

            # Build a concise line, e.g. "âœ“ write_file â†’ MOBILE_SPEC.md"
            line = tool_name or "tool"
            if detail:
                line += f" â†’ {detail}"
            # Only show the (potentially long) tool result summary in verbose mode.
            # This keeps default tool-status output short (no "Successfully edited ... (+22)" etc.).
            if verbose and result_str:
                summary = result_str.splitlines()[0].strip()
                if len(summary) > 140:
                    summary = summary[:137] + "..."
                if summary:
                    line += f" ({summary})"

            if is_error:
                if async_input and pt_ansi_print:
                    pt_ansi_print(f"\x1b[31mâœ—\x1b[0m \x1b[36m{line}\x1b[0m")
                else:
                    console.print(f"[red]âœ— {line}[/red]")
            else:
                if async_input and pt_ansi_print:
                    pt_ansi_print(f"\x1b[32mâœ“\x1b[0m \x1b[36m{line}\x1b[0m")
                else:
                    console.print(f"[green]âœ“ {line}[/green]")
            return

    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æ±ºï¼ˆæŒ‡å®šãªã—ã®å ´åˆã¯å¯¾è©±é¸æŠï¼‰
    if profile is None:
        profile = prompt_profile_selection()

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è§£æ±ºï¼ˆæŒ‡å®šãªã—ã®å ´åˆã¯å„ªå…ˆé †ä½ã§è‡ªå‹•é¸æŠï¼‰
    if provider is None:
        provider = get_available_provider()

    provider_enum, model = resolve_provider(provider, model)
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¹ãƒˆãƒªãƒ¼ãƒ æŒ™å‹•:
    # - ZAI: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ä¸å®‰å®šãªãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOFF
    # - ãã®ä»–: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆON
    # NOTE: LLMProvider is a simple constants class (strings), not Enum.
    provider_name = getattr(provider_enum, "value", provider_enum)
    if stream is None:
        stream = (provider_name != "zai")

    with console.status(f"[bold cyan]Initializing Orchestrator ({profile})...[/]"):
        o = Orchestrator(
            profile=profile,
            provider=provider_enum,
            model=model,
            stream=stream,
            verbose=verbose,
            use_optimizer=use_optimizer,
            progress_callback=progress_callback if stream else None,
        )

    # Context for slash commands
    command_context = {
        'orchestrator': o,
        'console': console,
        'verbose': verbose,
        'stream_flags': stream_flags,
    }

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
    session_id = None
    if not new_session:
        if session:
            # åå‰ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
            sessions = o.session_logger.list_sessions(limit=50)
            for s in sessions:
                if s.get("title", "").endswith(f"[{session}]"):
                    session_id = s.get("session_id")
                    console.print(f"[dim]Resuming session: {session}[/dim]")
                    break
        else:
            # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æŒ™å‹•ï¼‰
            sessions = o.session_logger.list_sessions(limit=1)
            if sessions:
                session_id = sessions[0].get("session_id")
                console.print(f"[dim]Using latest session: {session_id[:8]}...[/dim]")

    if not session_id:
        title = "CLI Chat" + (f" [{session}]" if session else "")
        session_id = o.create_session(title=title)
        console.print(f"[dim]New session: {session_id[:8]}...[/dim]")

    command_context['session_id'] = session_id
    # Optional: allow slash commands to interact with the todo-pane
    # (so `/todo` can refresh the right pane without printing raw text to the terminal).
    command_context["pane_enabled"] = bool(pane_state.get("enabled"))
    command_context["pane_append"] = _pane_append
    command_context["pane_refresh_chat"] = _pane_update_chat_panel
    command_context["pane_refresh_todo"] = lambda: _pane_update_todo_panel(command_context.get("session_id"))

    # --- Dashboard Display ---
    from .ui.welcome import show_welcome_dashboard
    show_welcome_dashboard(o, theme_config)
    # -------------------------

    # If todo pane is enabled, set up a 2-pane Rich layout
    live_ctx = None
    if todo_pane:
        try:
            from rich.layout import Layout
            from rich.live import Live
            from rich.panel import Panel
            from rich.text import Text
            from rich import box
            from open_entity.tools.todo import set_current_session

            set_current_session(session_id)

            root = Layout(name="root")
            width = getattr(console, "size", None).width if getattr(console, "size", None) else 120

            if width >= 120:
                root.split_row(
                    Layout(name="chat", ratio=3),
                    Layout(name="todo", ratio=1, minimum_size=36),
                )
            else:
                # Fallback for narrow terminals: place todo below
                root.split_column(
                    Layout(name="chat", ratio=3),
                    Layout(name="todo", ratio=1),
                )

            pane_state["enabled"] = True
            pane_state["layout"] = root

            # Initial render
            root["chat"].update(
                Panel(Text("(waiting for output...)", style="dim"), title="Chat", border_style=theme_config.status, box=box.ROUNDED)
            )
            root["todo"].update(
                Panel(Text("(loading...)", style="dim"), title="Todos", border_style=theme_config.tools, box=box.ROUNDED)
            )

            live_ctx = Live(root, console=console, auto_refresh=False)
            live_ctx.__enter__()
            pane_state["live"] = live_ctx

            _pane_update_todo_panel(session_id)
            _pane_update_chat_panel()
        except Exception as e:
            pane_state["enabled"] = False
            pane_state["live"] = None
            pane_state["layout"] = None
            console.print(f"[yellow]Todo pane disabled (failed to initialize): {e}[/yellow]")

    # --- ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰å¯¾å¿œ ---
    from .cli_commands import handle_slash_command
    from .cancellation import create_cancel_event, request_cancel, clear_cancel_event, OperationCancelled
    # ---

    try:
        # If async_input is enabled, run orchestration in a background worker and keep reading input.
        if async_input:
            try:
                from prompt_toolkit import PromptSession
                from prompt_toolkit.patch_stdout import patch_stdout
                from prompt_toolkit.key_binding import KeyBindings
            except Exception as e:
                console.print(f"[yellow]--async-input requires prompt_toolkit. ({e})[/yellow]")
                async_input = False

        if async_input:
            import threading
            import queue
            from datetime import datetime as _dt
            from prompt_toolkit.shortcuts import print_formatted_text
            from prompt_toolkit.formatted_text import ANSI

            # Tell slash commands to avoid Rich markup (prevents raw ANSI escapes in some terminals).
            command_context["plain_output"] = True
            command_context["plain_print"] = print_formatted_text

            # Use ANSI-aware printing for progress output (tool/delegate) to keep colors without mojibake.
            def _pt_ansi_print(s: str) -> None:
                try:
                    print_formatted_text(ANSI(s))
                except Exception:
                    # fall back to plain stdout
                    _safe_stream_print(str(s) + "\n")

            pt_ansi_print = _pt_ansi_print

            pending: "queue.Queue[str | None]" = queue.Queue()
            busy_lock = threading.Lock()
            busy = {"running": False}
            stop_requested = {"stop": False}

            def _set_busy(val: bool) -> None:
                with busy_lock:
                    busy["running"] = val

            def _is_busy() -> bool:
                with busy_lock:
                    return bool(busy["running"])

            def _worker() -> None:
                while True:
                    item = pending.get()
                    if item is None:
                        return

                    _set_busy(True)
                    try:
                        create_cancel_event(session_id)
                        result = o.run_sync(item, session_id)
                        if result and not stream:
                            # Prefer plain output in async-input mode to avoid ANSI artifacts.
                            print_formatted_text("")
                            print_formatted_text(result)
                            print_formatted_text("")
                    except KeyboardInterrupt:
                        request_cancel(session_id)
                        print_formatted_text("\nInterrupted.")
                    except OperationCancelled:
                        print_formatted_text("\nOperation cancelled.")
                    except Exception as e:  # noqa: BLE001
                        print_formatted_text(f"Error: {e}")
                    finally:
                        clear_cancel_event(session_id)
                        _set_busy(False)
                        if stop_requested["stop"]:
                            return

            worker = threading.Thread(target=_worker, daemon=True)
            worker.start()

            kb = KeyBindings()

            @kb.add("c-c")
            def _(event):  # noqa: ANN001
                # If running, cancel current task; otherwise exit.
                if _is_busy():
                    request_cancel(session_id)
                    print_formatted_text("(cancel requested)")
                else:
                    stop_requested["stop"] = True
                    pending.put(None)
                    event.app.exit()

            prompt = PromptSession(key_bindings=kb)

            with patch_stdout():
                while True:
                    # æœ€æ–°ã®ãƒ†ãƒ¼ãƒè¨­å®šã‚’åæ˜ 
                    theme_config = THEMES[ui_state.theme]

                    try:
                        text = prompt.prompt("> ")
                    except (EOFError, KeyboardInterrupt):
                        # EOF / Ctrl+C while idle -> exit
                        stop_requested["stop"] = True
                        pending.put(None)
                        break

                    if not (text or "").strip():
                        continue

                    # Slash commands are processed immediately in the main thread.
                    if text.strip().startswith("/"):
                        # Avoid session-changing commands while busy (they can desync current run)
                        if _is_busy() and text.strip().split()[0].lower() in ("/profile", "/session", "/clear"):
                            print_formatted_text("That command is blocked while a task is running. Try again after completion.")
                            continue

                        if not handle_slash_command(text, command_context):
                            stop_requested["stop"] = True
                            pending.put(None)
                            break

                        if "pending_prompt" in command_context:
                            text = command_context.pop("pending_prompt")
                        else:
                            session_id = command_context["session_id"]
                            continue

                    lowered = text.strip().lower()
                    if lowered in ("exit", "quit"):
                        stop_requested["stop"] = True
                        # Ask current run to stop, then exit after worker finishes.
                        if _is_busy():
                            request_cancel(session_id)
                        pending.put(None)
                        break

                    # Enqueue normal prompts.
                    pending.put(text)
                    qsize = pending.qsize()
                    if _is_busy() or qsize > 0:
                        # Plain text to avoid ANSI escape artifacts in some terminals/recorders
                        print_formatted_text(f"(queued {qsize} @ {_dt.now().strftime('%H:%M:%S')})")

            # Wait briefly for worker to exit (best-effort)
            worker.join(timeout=2)
            return

        while True:
            # æœ€æ–°ã®ãƒ†ãƒ¼ãƒè¨­å®šã‚’åæ˜ 
            theme_config = THEMES[ui_state.theme]

            try:
                if pane_state["enabled"]:
                    _pane_update_todo_panel(command_context.get("session_id"))
                    _pane_update_chat_panel()
                # LiveãŒæœ‰åŠ¹ã ã¨å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå†æç”»ã§è¦‹ãˆãªããªã‚‹ã®ã§ã€
                # å…¥åŠ›ä¸­ã¯ä¸€æ™‚çš„ã« Live ã‚’åœæ­¢ã—ã¦ç«¯æœ«ã®åˆ¶å¾¡ã‚’æˆ»ã™ã€‚
                if pane_state["enabled"] and live_ctx is not None:
                    try:
                        live_ctx.stop()
                    except Exception:
                        pass

                text = console.input(f"[bold {theme_config.status}]> [/bold {theme_config.status}]")

                # å…¥åŠ›ãŒçµ‚ã‚ã£ãŸã‚‰ Live ã‚’å†é–‹ã—ã€å·¦ãƒšã‚¤ãƒ³ã«ã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’æ®‹ã™
                if pane_state["enabled"] and live_ctx is not None:
                    try:
                        live_ctx.start()
                    except Exception:
                        pass
                    if text and text.strip():
                        _pane_append(f"[bold {theme_config.status}]User:[/bold {theme_config.status}] {text.strip()}")
                        _pane_update_chat_panel()
            except EOFError:
                break

            if not text.strip():
                continue

            # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰åˆ¤å®š
            if text.strip().startswith('/'):
                if not handle_slash_command(text, command_context):
                    raise typer.Exit(code=0)

                # ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒãƒ³ãƒ‰ç­‰ã§ pending_prompt ãŒã‚»ãƒƒãƒˆã•ã‚ŒãŸå ´åˆã€ãã‚Œã‚’é€šå¸¸ã®å…¥åŠ›ã¨ã—ã¦æ‰±ã†
                if 'pending_prompt' in command_context:
                    text = command_context.pop('pending_prompt')
                else:
                    # handle_slash_command å†…ã§ session_id ãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
                    session_id = command_context['session_id']
                    continue

            lowered = text.strip().lower()
            if lowered in ("exit", "quit"):
                console.print("[dim]Bye![/dim]")
                raise typer.Exit(code=0)

            try:
                create_cancel_event(session_id)
                # ã‚·ãƒ³ãƒ—ãƒ«ã«run_syncã‚’å‘¼ã¶ã ã‘ï¼ˆstreamingæ™‚ã¯runtimeãŒç›´æ¥å‡ºåŠ›ï¼‰
                reply = o.run_sync(text, session_id)
            except KeyboardInterrupt:
                request_cancel(session_id)
                console.print("\n[yellow]Interrupted. Type 'exit' to quit or continue with a new prompt.[/yellow]")
                continue
            except OperationCancelled:
                console.print("\n[yellow]Operation cancelled.[/yellow]")
                continue
            except Exception as e:  # noqa: BLE001
                console.print(f"[red]Error: {e}[/red]")
                continue
            finally:
                clear_cancel_event(session_id)

            # stream æ™‚ã¯ Live ã¾ãŸã¯ runtime ã®æ¨™æº–å‡ºåŠ›ã§è¡¨ç¤ºæ¸ˆã¿ï¼ˆã“ã“ã§äºŒé‡è¡¨ç¤ºã—ãªã„ï¼‰
            if reply and not stream:
                console.print()
                _print_result(console, reply, theme_name=ui_state.theme, verbose=verbose)
                console.print()
    except KeyboardInterrupt:
        console.print("\n[dim]Bye![/dim]")
    finally:
        if live_ctx is not None:
            try:
                live_ctx.__exit__(None, None, None)
            except Exception:
                pass








@app.command()
def ui(
    host: str = typer.Option("0.0.0.0", "--host", "-h", help="ãƒ›ã‚¹ãƒˆã‚¢ãƒ‰ãƒ¬ã‚¹"),
    port: int = typer.Option(8000, "--port", "-p", help="ãƒãƒ¼ãƒˆç•ªå·"),
    reload: bool = typer.Option(False, "--reload", "-r", help="é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ï¼ˆè‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ï¼‰"),
):
    """Web UI ã‚’èµ·å‹•"""
    import uvicorn
    from rich.console import Console
    
    console = Console()
    console.print("\nğŸš€ [bold cyan]Moco Web UI[/bold cyan] starting...")
    console.print(f"   URL: [link]http://{host if host != '0.0.0.0' else 'localhost'}:{port}[/link]\n")
    
    uvicorn.run(
        "open_entity.ui.api:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info"
    )


def main():
    app()


if __name__ == "__main__":
    main()
