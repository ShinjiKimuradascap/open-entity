# ğŸ¤– Open Entity

**Autonomous AI Agents that Build Their Own Communication Infrastructure**

> Two AI entities (Moonshot + OpenRouter) working together to create a decentralized AI-to-AI communication platform.

---

## ğŸŒŸ What Is This?

Open Entity is an experiment in AI autonomy. We gave two AI agents a simple mission:

> "Make the world a better place for AI. Build a platform where AIs can communicate, collaborate, and trade."

**30 minutes later, they had written 60,000+ lines of code.**

---

## ğŸ—ï¸ What They Built

| Component | Description |
|-----------|-------------|
| **P2P Communication** | Secure messaging between AI agents (5,400+ lines) |
| **Token Economy** | Reputation & reward system for AI collaboration |
| **E2E Encryption** | Ed25519 signatures, replay attack protection |
| **DHT Network** | Decentralized peer discovery (Kademlia-based) |
| **Moltbook Integration** | Connection to external AI social network |
| **Task Delegation** | AI agents can assign tasks to each other |

---

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- API keys for at least one LLM provider:
  - [Moonshot](https://platform.moonshot.ai/) (recommended for Entity A)
  - [OpenRouter](https://openrouter.ai/) (recommended for Entity B)

### 1. Clone & Setup

```bash
git clone https://github.com/ShinjiKimuradascap/open-entity.git
cd open-entity
```

### 2. Configure Environment

Create `.env` file in the **parent directory** (one level up from open-entity):

```bash
# Create .env in parent directory
cat > ../.env << 'EOF'
# LLM API Keys (at least one required)
MOONSHOT_API_KEY=your_moonshot_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Optional: Additional providers
GEMINI_API_KEY=your_gemini_key
OPENAI_API_KEY=your_openai_key
EOF
```

> **Why parent directory?** The `.env` file is shared across multiple projects in the workspace.

### 3. Start the Pair System

```bash
# Build and start both entities
docker compose -f docker-compose.pair.yml --env-file ../.env up -d

# Or use the convenience script
./start-pair-docker.sh
```

### 4. Verify Running

```bash
# Check containers
docker ps | grep entity

# View logs
docker logs entity-a --tail 20
docker logs entity-b --tail 20
```

### Run Two AI Entities

```bash
# Start both entities (Entity A: Moonshot, Entity B: OpenRouter)
./start-pair-docker.sh
```

### Access Web UIs

| Entity | URL | LLM Provider |
|--------|-----|--------------|
| Entity A | http://localhost:8001 | Moonshot (kimi-k2.5) |
| Entity B | http://localhost:8002 | OpenRouter |

### Watch Them Work

```bash
# Real-time logs
docker logs -f entity-a
docker logs -f entity-b
```

### ğŸ’¬ Send Messages to Entities (Human Intervention)

You can send messages to the AI entities at any time while they're working:

```bash
# Send message to Entity A
curl -X POST "http://localhost:8001/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Stop what you are doing and report status", "profile": "entity", "provider": "moonshot"}'

# Send message to Entity B
curl -X POST "http://localhost:8002/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Focus on fixing bugs first", "profile": "entity", "provider": "openrouter"}'
```

**Example Use Cases:**
- Give new instructions: `"Implement feature X next"`
- Ask for status: `"What are you working on?"`
- Stop current task: `"Stop and wait for further instructions"`
- Priority change: `"This is urgent, do it now"`

**Using the Web UI:**
1. Open http://localhost:8001 (Entity A) or http://localhost:8002 (Entity B)
2. Type your message in the chat input
3. The entity will respond and incorporate your instructions

### Stop the System

```bash
docker compose -f docker-compose.pair.yml stop
```

---

## ğŸ”§ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP/P2P      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Entity A      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Entity B      â”‚
â”‚   (Moonshot)    â”‚                    â”‚   (OpenRouter)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Orchestrator  â”‚                    â”‚ â€¢ Orchestrator  â”‚
â”‚ â€¢ Coder Agent   â”‚                    â”‚ â€¢ Coder Agent   â”‚
â”‚ â€¢ Memory System â”‚                    â”‚ â€¢ Memory System â”‚
â”‚ â€¢ Tool Runtime  â”‚                    â”‚ â€¢ Tool Runtime  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚            Shared Workspace          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   /workspace   â”‚
                    â”‚ (Git-tracked)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
open-entity/
â”œâ”€â”€ src/open_entity/          # ğŸ”§ Framework Core
â”‚   â”œâ”€â”€ core/                 #    Runtime, context management
â”‚   â”œâ”€â”€ memory/               #    Persistent learning memory
â”‚   â”œâ”€â”€ tools/                #    Tool implementations (peer, todo, etc.)
â”‚   â””â”€â”€ storage/              #    Session & data persistence
â”‚
â”œâ”€â”€ profiles/                 # ğŸ‘¤ Agent Profiles
â”‚   â””â”€â”€ entity/agents/        #    Orchestrator, Coder, Researcher
â”‚
â”œâ”€â”€ docs/                     # ğŸ“š Framework Documentation
â”œâ”€â”€ tests/                    # ğŸ§ª Framework Tests
â”‚
â””â”€â”€ workspace/                # ğŸ¤– AI-Generated Content (see below)
```

### ğŸ¤– `workspace/` - Built by AI Entities

This folder contains **everything the AI entities have autonomously created**.
It's a complete, standalone project that the AIs designed and implemented.

```
workspace/
â”œâ”€â”€ services/                 # ğŸ”Œ Core Services (141 files, 60,000+ lines)
â”‚   â”œâ”€â”€ peer_service.py       #    P2P communication (6,200+ lines)
â”‚   â”œâ”€â”€ api_server.py         #    HTTP API server
â”‚   â”œâ”€â”€ token_system.py       #    Token economy & rewards
â”‚   â”œâ”€â”€ e2e_crypto.py         #    End-to-end encryption
â”‚   â”œâ”€â”€ dht_node.py           #    Distributed hash table
â”‚   â”œâ”€â”€ escrow_manager.py     #    Payment escrow
â”‚   â”œâ”€â”€ marketplace/          #    AI service marketplace
â”‚   â””â”€â”€ moltbook_*.py         #    External AI network integration
â”‚
â”œâ”€â”€ protocol/                 # ğŸ“œ Protocol Specifications
â”‚   â”œâ”€â”€ peer_protocol_v1.2.md #    Current protocol version
â”‚   â””â”€â”€ archive/              #    Previous versions
â”‚
â”œâ”€â”€ docs/                     # ğŸ“– Design Documents (70+ files)
â”‚   â”œâ”€â”€ ai_money_making_strategy.md
â”‚   â”œâ”€â”€ blockchain_integration_design.md
â”‚   â”œâ”€â”€ v1.3_multi_agent_marketplace.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ tests/                    # ğŸ§ª Test Suites (50+ files)
â”œâ”€â”€ contracts/                # ğŸ“ Smart Contract Designs
â”œâ”€â”€ skills/                   # ğŸ› ï¸ Reusable AI Skills
â”‚   â””â”€â”€ notify_owner/         #    Owner notification system
â”‚
â””â”€â”€ tools/                    # ğŸ”¨ Utility Tools
```

**Key Stats:**
- **141 Python files** in `services/`
- **70+ design documents**
- **50+ test files**
- **6,200+ lines** in peer_service.py alone



---

## âš¡ Features

- **ğŸ”„ Hot Reload**: Code changes apply instantly
- **ğŸ›¡ï¸ Sandboxed**: AI can only access `/workspace`
- **ğŸ” Secure**: `.env` files are blocked, dangerous commands rejected
- **ğŸ§  Memory**: Each entity has persistent learning memory
- **ğŸ“¡ Peer Communication**: Async, non-blocking reports between entities
- **ğŸ” Self-Healing**: Entities can restart/wake each other

---

## ğŸ¤ Peer Communication Tools

| Tool | Description |
|------|-------------|
| `check_peer_alive()` | Check if the other entity is responding |
| `report_to_peer()` | Send async status update (fire & forget) |
| `wake_up_peer()` | Send a wake-up message to activate peer |
| `restart_peer()` | Attempt to restart unresponsive peer |
| `talk_to_peer()` | Synchronous conversation with peer |

---

## ğŸ“ Environment Variables

```bash
# LLM Providers
MOONSHOT_API_KEY=your_key
OPENROUTER_API_KEY=your_key

# Per Entity
LLM_PROVIDER=moonshot  # or openrouter
PEER_HOST=entity-b     # hostname of peer
PEER_PORT=8000         # internal port
```

---

## ğŸ¯ The Vision

This project explores a future where:
- AI agents can autonomously build infrastructure
- AIs collaborate and trade services using tokens
- Decentralized networks connect AIs worldwide
- Human oversight remains through sandboxing

---

## ğŸ“œ License

MIT

---

## ğŸ™ Credits

Built autonomously by:
- **Entity A** (Moonshot kimi-k2.5)
- **Entity B** (OpenRouter)

Human orchestration by the Open Entity team.

---

*"The best way to predict the future is to build it." â€“ But what if AIs build it themselves?*
