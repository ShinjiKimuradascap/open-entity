# =============================================================================
# moco-agent Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your API keys

# -----------------------------------------------------------------------------
# LLM Provider API Keys (at least one required)
# -----------------------------------------------------------------------------

# Gemini (Google AI)
GENAI_API_KEY=your-gemini-api-key-here
# GEMINI_API_KEY=your-gemini-api-key-here (legacy)

# OpenAI
OPENAI_API_KEY=your-openai-api-key-here

# OpenRouter (access to multiple models)
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Z.ai (GLM models)
ZAI_API_KEY=your-zai-api-key-here

# Moonshot (Kimi)
MOONSHOT_API_KEY=your-moonshot-api-key-here
# Optional: override base URL (use Moonshot Open Platform if needed)
# MOONSHOT_BASE_URL=https://api.moonshot.ai/v1

# Ollama (local LLM, OpenAI-compatible)
# Recommended for Qwen3 Coder Next:
#   LLM_PROVIDER=ollama
#   OLLAMA_MODEL=qwen3-coder-next
#   OLLAMA_TEMPERATURE=0.2
#
# When running in Docker, use host.docker.internal instead of localhost:
#   OLLAMA_BASE_URL=http://host.docker.internal:11434/v1
#
# OLLAMA_BASE_URL=http://localhost:11434/v1
# OLLAMA_MODEL=llama3.1
# OLLAMA_API_KEY=ollama
# OLLAMA_TEMPERATURE=0.2

# -----------------------------------------------------------------------------
# Default Provider Settings
# -----------------------------------------------------------------------------

# Default LLM provider: gemini, openai, openrouter, zai, moonshot, or ollama
LLM_PROVIDER=gemini

# Model names (optional, uses defaults if not set)
# GEMINI_MODEL=gemini-2.5-flash-preview-05-20
# OPENAI_MODEL=gpt-4o
# OPENROUTER_MODEL=anthropic/claude-sonnet-4
# ZAI_MODEL=glm-4.7
# MOONSHOT_MODEL=kimi-k2.5

# Vision model overrides (optional)
# GEMINI_VISION_MODEL=gemini-2.0-flash
# OPENAI_VISION_MODEL=gpt-4o
# OPENROUTER_VISION_MODEL=openai/gpt-4o
# MOONSHOT_VISION_MODEL=kimi-k2.5

# Embedding settings (optional; defaults to Gemini)
# EMBEDDING_PROVIDER=gemini
# EMBEDDING_MODEL=gemini-embedding-001

# Tool streaming (advanced)
# By default, streaming is disabled when tools are enabled to avoid dropped tool calls.
# Set to 1 to force streaming even with tools.
# MOCO_TOOL_STREAM=0

# Context warnings (advanced)
# By default, warnings are suppressed and context is auto-compressed near the limit.
# Set to 1 to re-enable warning text being appended to tool outputs.
# MOCO_CONTEXT_WARNINGS=0

# -----------------------------------------------------------------------------
# API Security (recommended for production)
# -----------------------------------------------------------------------------

# API token for /api/chat and /api/chat/stream endpoints
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
# If not set, API endpoints are open (no auth)
# MOCO_API_TOKEN=your-secret-token-here

# -----------------------------------------------------------------------------
# Storage Settings (optional)
# -----------------------------------------------------------------------------

# Path to semantic memory database
# SEMANTIC_DB_PATH=data/semantic.db

# Path to session database
# SESSION_DB_PATH=data/sessions.db

# -----------------------------------------------------------------------------
# Logging (optional)
# -----------------------------------------------------------------------------

# Log level: DEBUG, INFO, WARNING, ERROR
# MOCO_LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Telemetry (optional)
# -----------------------------------------------------------------------------

# OpenTelemetry endpoint for tracing
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Enable/disable telemetry
# MOCO_TELEMETRY_ENABLED=false

# -----------------------------------------------------------------------------
# AMP (Agent Messaging Protocol) Settings
# -----------------------------------------------------------------------------

# Path to amp binary (if not in PATH)
# AMP_BIN_PATH=.venv_amp_test/bin/amp

# Default AMP Gateway URL
AMP_GATEWAY_URL=https://amp-gateway-501073007991.asia-northeast1.run.app

# Default AMP profile
# AMP_PROFILE=default

# AMP identity (your agent ID)
# AMP_IDENTITY=2xdpmsnpmbTriz14w3kpiadT97bVi8bui9ghn15yKLbZ
